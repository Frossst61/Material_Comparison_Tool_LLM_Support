#!/usr/bin/env python3
"""
Test script to verify the model in project root works correctly
"""

import os
from pathlib import Path

def check_model_structure():
    """Check if the model folder structure is correct"""
    model_name = 'paraphrase-multilingual-MiniLM-L12-v2'
    model_path = Path(model_name)
    
    print(f"ğŸ” Checking model structure: {model_path}")
    
    if not model_path.exists():
        print(f"âŒ Model folder not found: {model_path}")
        print("   Please follow MANUAL_MODEL_SETUP.md to set up the model")
        return False
    
    # Required files
    required_files = [
        'config.json',
        'config_sentence_transformers.json',
        'sentence_bert_config.json',
        'modules.json',
        'model.safetensors',  # This is the most important one
    ]
    
    missing_files = []
    existing_files = []
    
    for file_name in required_files:
        file_path = model_path / file_name
        if file_path.exists():
            size = file_path.stat().st_size
            size_mb = size / (1024 * 1024)
            existing_files.append(f"âœ… {file_name} ({size_mb:.1f} MB)")
        else:
            missing_files.append(f"âŒ {file_name}")
    
    print("\nModel files status:")
    for file_info in existing_files:
        print(f"  {file_info}")
    for file_info in missing_files:
        print(f"  {file_info}")
    
    # Check the most critical file
    model_weights = model_path / 'model.safetensors'
    if model_weights.exists():
        size_mb = model_weights.stat().st_size / (1024 * 1024)
        if size_mb > 400:  # Should be around 471MB
            print(f"\nâœ… Model weights file looks good: {size_mb:.1f} MB")
        else:
            print(f"\nâš ï¸  Model weights file seems small: {size_mb:.1f} MB (expected ~471MB)")
            print("   File might be incomplete")
    else:
        print(f"\nâŒ Critical file missing: model.safetensors")
        print("   This file contains the neural network weights and is essential")
    
    return len(missing_files) == 0

def test_model_loading():
    """Test loading and using the model"""
    try:
        from sentence_transformers import SentenceTransformer
        print("\nâœ… sentence-transformers library is available")
    except ImportError:
        print("\nâŒ sentence-transformers not installed")
        print("   Run: pip install sentence-transformers")
        return False
    
    model_name = 'paraphrase-multilingual-MiniLM-L12-v2'
    
    try:
        print(f"\nğŸ”„ Loading model from: ./{model_name}")
        model = SentenceTransformer(model_name)
        print("âœ… Model loaded successfully!")
        
        # Test encoding
        print("\nğŸ§ª Testing model encoding...")
        test_sentences = [
            "steel",
            "aluminum", 
            "copper",
            "stainless steel",
            "aluminium alloy"
        ]
        
        embeddings = model.encode(test_sentences)
        print(f"âœ… Encoding successful! Shape: {embeddings.shape}")
        
        # Test similarity calculation
        from sklearn.metrics.pairwise import cosine_similarity
        similarity_matrix = cosine_similarity(embeddings)
        print(f"âœ… Similarity calculation works! Matrix shape: {similarity_matrix.shape}")
        
        # Show some similarities
        print(f"\nSample similarities:")
        print(f"  steel â†” stainless steel: {similarity_matrix[0][3]:.3f}")
        print(f"  aluminum â†” aluminium alloy: {similarity_matrix[1][4]:.3f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Model loading/testing failed: {e}")
        return False

def update_main_code():
    """Update the main code to use the root model"""
    print(f"\nğŸ”§ The main code (test.py) is already configured to:")
    print(f"   1. Look for models in the project root")
    print(f"   2. Use paraphrase-multilingual-MiniLM-L12-v2 by default")
    print(f"   3. Fall back gracefully if model not available")
    print(f"\nâœ… No code changes needed - everything is ready!")

def main():
    """Main test function"""
    print("ğŸ§ª Testing Model in Project Root")
    print("=" * 50)
    
    # Check structure
    structure_ok = check_model_structure()
    
    if structure_ok:
        # Test loading
        loading_ok = test_model_loading()
        
        if loading_ok:
            print("\n" + "=" * 50)
            print("ğŸ‰ SUCCESS! Model is working perfectly!")
            print("\nğŸ“‹ What works now:")
            print("  âœ… Model is in project root")
            print("  âœ… All required files present")
            print("  âœ… Model loads and encodes text")
            print("  âœ… Similarity calculations work")
            print("  âœ… Ready for offline material comparison!")
            
            update_main_code()
            
            print(f"\nğŸš€ You can now use:")
            print(f"   python demo_offline.py")
            print(f"   # Or use the LLM mode directly in your code")
            
        else:
            print(f"\nâš ï¸  Model files found but loading failed")
            print(f"   Check MANUAL_MODEL_SETUP.md for troubleshooting")
    else:
        print(f"\nâŒ Model setup incomplete")
        print(f"   Please follow MANUAL_MODEL_SETUP.md to download the model")

if __name__ == "__main__":
    main()
